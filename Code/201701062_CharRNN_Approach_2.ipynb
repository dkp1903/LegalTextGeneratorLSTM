{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "201701062_CharRNN_Approach_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA6ssEPnYiBR",
        "colab_type": "text"
      },
      "source": [
        "**Legal Text Generation using Recurrent Neural Networks**\n",
        "\n",
        "**Dushyant Pathak**\n",
        "\n",
        "**201701062**\n",
        "\n",
        "**A slightly modified, uncustomized approach.**\n",
        "\n",
        "1.   Used inbuilt one hot function to compare the results\n",
        "2.   Smaller dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iokuQUsJI2U",
        "colab_type": "code",
        "outputId": "0308bfb9-ef83-4731-e5c7-82bad7493365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJHeR_2ESIAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import os, io, sys, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import one_hot\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Activation, Dropout, Input, Lambda, Reshape, Masking\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical, plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83PeaGO82CB9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "9f1ca47c-aef9-4033-c01a-9217a9b0a202"
      },
      "source": [
        "  ## Data Fetch and Clean\n",
        "\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "path_to_file = \"/content/drive/My Drive/data_1.txt\"\n",
        "path_to_test = \"/content/drive/My Drive/test.txt\"\n",
        "\n",
        "with io.open(path_to_file, encoding='utf-8') as corpus:\n",
        "    text = corpus.read()\n",
        "\n",
        "## Total number of chars in the vocabulary - with repetition\n",
        "LENGTH = len(text)\n",
        "\n",
        "\n",
        "Tx = 11 # length of each example in characters \n",
        "\n",
        "vocab = sorted(set(list(text))) # Set of all the characters in the corpus - to remove redundancies\n",
        "\n",
        "## Mapping all characters to indices by enumerating all chars present\n",
        "char_to_indices = dict((ch, idx) for idx, ch in enumerate(vocab))\n",
        "## Mapping chars to indices \n",
        "index_to_char = dict((idx, ch) for idx, ch in enumerate(vocab))\n",
        "\n",
        "sentences = [] # X\n",
        "mapped_chars = [] # Y\n",
        "\n",
        "step = 3\n",
        "\n",
        "for i in range(0, LENGTH - Tx, step):\n",
        "    temp_text = text[i: i+Tx]\n",
        "    sentences.append(temp_text[:-1])\n",
        "    mapped_chars.append(temp_text[-1])\n",
        "\n",
        "m = len(sentences)\n",
        "\n",
        "X = np.zeros((m, Tx - 1, len(vocab)))\n",
        "Y = np.zeros((m, len(vocab)))\n",
        "\n",
        "## One hot encoding the chars, per example(sentence wise)\n",
        "for i, example in enumerate(sentences):\n",
        "    X[i, :, :] = one_hot([char_to_indices[ch] for ch in example], depth=len(vocab))\n",
        "    Y[i, :] = one_hot(char_to_indices[mapped_chars[i]], depth=len(vocab))\n",
        "\n",
        "# Conversion to Numpy array for ease of use\n",
        "X = np.asarray(X)\n",
        "Y = np.asarray(Y)\n",
        "\n",
        "#==============printing data dimesions=========================================\n",
        "print(f\"Length of corpus: {LENGTH}\")\n",
        "print(f\"X.shape = {X.shape}\")\n",
        "print(f\"Y.shape = {Y.shape}\")\n",
        "print(f\"Number of examples: {m}\") "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of corpus: 415756\n",
            "X.shape = (138582, 10, 91)\n",
            "Y.shape = (138582, 91)\n",
            "Number of examples: 138582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kzEifE0OT_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_example(index = None):\n",
        "    \n",
        "    ## retrieves the example at index position in X is index is passed, otherwise random example is obtained\n",
        "    ## :param index: index of example desired to be retrieved\n",
        "    ## :return: string of text\n",
        "    \n",
        "\n",
        "    if index is None:\n",
        "        index = np.random.randint(low=0, high=m)\n",
        "\n",
        "    curr_x = [index_to_char[idx] for idx in np.argmax(X[index, :, :], axis=1)]\n",
        "    curr_y = index_to_char[np.argmax(Y[index, :])]\n",
        "\n",
        "    x_y = (''.join(curr_x), curr_y)\n",
        "\n",
        "    return x_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpYgE7ygSLTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "4a994746-0b5a-4d16-e4e0-cb8c9260df3d"
      },
      "source": [
        "\"\"\"\n",
        "testing a single example and the time it took to retrieve it\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "\n",
        "start = time.process_time()\n",
        "example = get_example()\n",
        "end = time.process_time()\n",
        "\n",
        "print(f\"Sample X: {example[0]}\\nCorresponding Y: {example[1]}\")\n",
        "print(f\"\\nTime taken for acquiring this example: {end - start} seconds\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample X:  on object\n",
            "Corresponding Y: i\n",
            "\n",
            "Time taken for acquiring this example: 0.0004414549999864903 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPLZQqNSwuah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "network architecture creation\n",
        "model creation\n",
        "plot_model allows me to see what my neural network looks like\n",
        "\"\"\"\n",
        "\n",
        "def lstm_model(Tx, vocab, output_length):\n",
        "  # network architecture LSTM -> Dropout -> Reshape -> LSTM -> Dropout -> Dense\n",
        "\n",
        "  # define the initial hidden state a0 and initial cell state c0\n",
        "  a0 = Input(shape=(output_length,), name='a0')\n",
        "  c0 = Input(shape=(output_length,), name='c0')\n",
        "  a = a0\n",
        "  c = c0\n",
        "\n",
        "  X = Input(shape=(Tx, len(vocab)), name='X')\n",
        "  \n",
        "  a, _, c = LSTM(units=output_length, activation='tanh', return_state=True, dtype='float32', name=f'lstm_1')(X, [a, c])\n",
        "  a = Dropout(rate=0.2, name=f'dropout_1')(a)\n",
        "  a = Reshape((1, output_length), name='reshape_1')(a) # needed after a dropout layer for another LSTM layer\n",
        "  a = LSTM(units=output_length, activation='tanh', dtype='float32', name=f'lstm_2')(a)\n",
        "  a = Dropout(rate=0.2, name=f'dropout_2')(a)\n",
        "  out = Dense(units=len(vocab), activation='softmax', name=f'dense')(a)\n",
        "    \n",
        "  model = Model(inputs=[X, a0, c0], outputs=out, name='lstm_model')\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GTikSyoerWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "90961741-8abd-4530-fc88-cd23ded25110"
      },
      "source": [
        "\"\"\"\n",
        "creating the model and the summary of it\n",
        "\"\"\"\n",
        "#====================Creating important variables===============================\n",
        "n_a = 256 # number of hidden state dimensions for each LSTM cell\n",
        "\n",
        "a0 = np.zeros((m, n_a))\n",
        "c0 = np.zeros((m, n_a))\n",
        "#===============================================================================\n",
        "\n",
        "model = lstm_model(Tx=Tx - 1, vocab=vocab, output_length=n_a)\n",
        "\n",
        "plot_model(model, to_file='/content/drive/My Drive/nn_graph.png')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"lstm_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "X (InputLayer)                  [(None, 10, 91)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "a0 (InputLayer)                 [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "c0 (InputLayer)                 [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 256), (None, 356352      X[0][0]                          \n",
            "                                                                 a0[0][0]                         \n",
            "                                                                 c0[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 256)          0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 256)       0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 256)          525312      reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 256)          0           lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 91)           23387       dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 905,051\n",
            "Trainable params: 905,051\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFzkBWLkMA94",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "b555c806-f920-4344-b424-d8872150378d"
      },
      "source": [
        "learning_rate = 0.01\n",
        "learning_rate_decay = 0.001\n",
        "\n",
        "optimizer = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, decay=learning_rate_decay)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "model.fit([X, a0, c0], Y, batch_size=batch_size, epochs=10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1386/1386 [==============================] - 15s 11ms/step - loss: 1.8209 - accuracy: 0.4879\n",
            "Epoch 2/10\n",
            "1386/1386 [==============================] - 16s 11ms/step - loss: 1.1776 - accuracy: 0.6592\n",
            "Epoch 3/10\n",
            "1386/1386 [==============================] - 15s 11ms/step - loss: 1.0217 - accuracy: 0.7011\n",
            "Epoch 4/10\n",
            "1386/1386 [==============================] - 15s 11ms/step - loss: 0.9318 - accuracy: 0.7251\n",
            "Epoch 5/10\n",
            "1386/1386 [==============================] - 15s 11ms/step - loss: 0.8713 - accuracy: 0.7398\n",
            "Epoch 6/10\n",
            "1386/1386 [==============================] - 15s 11ms/step - loss: 0.8233 - accuracy: 0.7523\n",
            "Epoch 7/10\n",
            "1386/1386 [==============================] - 15s 11ms/step - loss: 0.7832 - accuracy: 0.7636\n",
            "Epoch 8/10\n",
            "1386/1386 [==============================] - 15s 11ms/step - loss: 0.7503 - accuracy: 0.7738\n",
            "Epoch 9/10\n",
            "1386/1386 [==============================] - 15s 11ms/step - loss: 0.7240 - accuracy: 0.7803\n",
            "Epoch 10/10\n",
            "1386/1386 [==============================] - 15s 11ms/step - loss: 0.6995 - accuracy: 0.7871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fac201f2048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXexPfExcpNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Shows the model\n",
        "\n",
        "filepath = '/content/drive/My Drive/dkp_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnrScYNaRlFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/dkp_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HojRFbuhdgze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_model = load_model(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw-XXtYuYJ-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12938f84-89ee-4d0f-b3d4-72c90f065399"
      },
      "source": [
        "accuracy = lstm_model.evaluate([X, a0, c0], Y, verbose=0)[1]\n",
        "print(f\"Accuracy on the training set: {round(accuracy*100, 4)}%\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on the training set: 82.4537%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHJwSspvMVkp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "outputId": "173fe70c-6df2-4003-8dd5-31ae4b4c7387"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds) \n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def generate_output():\n",
        "      diversity = random.choice([0.2, 0.5, 0.7, 1.0, 1.2, 1.4])\n",
        "      diversity = 0.2\n",
        "      print(f'Diversity: {diversity}')\n",
        "      generated = ''\n",
        "      sentence = 'The government proposes'\n",
        "      generated += sentence\n",
        "      if len(sentence) > 10:\n",
        "        sentence = sentence[:10]\n",
        "      elif len(sentence) < 10:\n",
        "        rem = 10 - len(sentence)\n",
        "        sentence += ' ' * rem\n",
        "      sys.stdout.write(generated + ' ')\n",
        "      a0 = np.zeros((1, n_a))\n",
        "      c0 = np.zeros((1, n_a))\n",
        "      sys.stdout.write(sentence)\n",
        "      for i in range(1000):\n",
        "          x_pred = np.zeros((1, Tx-1, len(vocab)))\n",
        "          for t, char in enumerate(sentence):\n",
        "              if char != '0':\n",
        "                  x_pred[0, t, char_to_indices[char]] = 1.\n",
        "          preds = lstm_model.predict([x_pred, a0, c0], verbose=0)[0]\n",
        "          next_index = sample(preds, temperature = 1.0)\n",
        "          next_char = index_to_char[next_index]\n",
        "\n",
        "          generated += next_char\n",
        "          sentence = sentence[1:] + next_char\n",
        "\n",
        "          sys.stdout.write(next_char)\n",
        "          sys.stdout.flush()\n",
        "\n",
        "          if next_char == '\\n':\n",
        "              print('\\n')\n",
        "          elif next_char == '\\t':\n",
        "              print('\\t')\n",
        "\n",
        "generate_output()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diversity: 0.2\n",
            "The government proposes The governmental authority of the Other Party shall not \n",
            "\n",
            "\n",
            "be made to the applicable laws and regulations. The measure or licences the former Party or they to promoting \n",
            "\n",
            "\n",
            "good through a means Xhat increased import \n",
            "\n",
            "\n",
            "to adopts or maintain a Tribunal shall be made in the part shall, in its Schedule in Annex 7(M) effort Deter prior to arbitration procedures, do not used by any produced or but and the administrative vaw of the equity to an international law berelate in agriculture. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2. The Parties. Each Party shall grounds in \n",
            "\n",
            "\n",
            "resultions on     (vii) the term “strIgtar rights of inconsimed in Part 2 of the service supplier requirements specific commitment, on the rate laws and regulations, a goods for the objective rew insurational international legal \n",
            "\n",
            "\n",
            "measure Disputing such in directive, nothondings do not carry ad leasure commercial creditted shall be applied. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(b) \t\t\n",
            "with respect to Japan, investment app)icated \n",
            "\n",
            "\n",
            "2 or  \n",
            "\n",
            "\n",
            "bo nationals, provided from a Trade in this Chapter and \n",
            "\n",
            "\n",
            "information within 15"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}